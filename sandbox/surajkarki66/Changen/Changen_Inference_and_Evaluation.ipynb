{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GThGh4Pmdk9",
        "outputId": "c6c552df-5a3d-4332-b289-5ab0827d0704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Changen'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 47 (delta 21), reused 33 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (47/47), 16.94 KiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "Collecting ever-beta\n",
            "  Downloading ever_beta-0.5.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ever-beta) (1.26.4)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from ever-beta) (3.13.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from ever-beta) (11.1.0)\n",
            "Requirement already satisfied: albumentations>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from ever-beta) (1.4.20)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.11/dist-packages (from ever-beta) (2.18.0)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from ever-beta) (2025.1.10)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from ever-beta) (0.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ever-beta) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from ever-beta) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ever-beta) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ever-beta) (2.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations>=0.4.2->ever-beta) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations>=0.4.2->ever-beta) (2.10.6)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.11/dist-packages (from albumentations>=0.4.2->ever-beta) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.11/dist-packages (from albumentations>=0.4.2->ever-beta) (0.2.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations>=0.4.2->ever-beta) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.19->albumentations>=0.4.2->ever-beta) (3.11.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->ever-beta) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ever-beta) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ever-beta) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ever-beta) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ever-beta) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ever-beta) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ever-beta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ever-beta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ever-beta) (2025.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->ever-beta) (0.2.13)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->ever-beta) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->ever-beta) (2.36.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->ever-beta) (0.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations>=0.4.2->ever-beta) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations>=0.4.2->ever-beta) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations>=0.4.2->ever-beta) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.14->ever-beta) (3.0.2)\n",
            "Downloading ever_beta-0.5.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ever-beta\n",
            "Successfully installed ever-beta-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Z-Zheng/Changen.git\n",
        "!pip install ever-beta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Changen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFuxYwNIvt7y",
        "outputId": "42c8fa04-508f-4192-ee63-33a9780283b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Changen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('Z-Zheng/Changen', 'changestar_1x96', backbone_name='r18',\n",
        "               pretrained=True, dataset_name='levircd', force_reload=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t-PMc2GmlSR",
        "outputId": "0e1bcfdb-da9a-442f-a05f-ba916ed6094c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/Z-Zheng/Changen/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.2 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "2025-02-01 09:27:56, INFO:ever.core.logger:ResNetEncoder: pretrained = False\n",
            "Downloading: \"https://github.com/Z-Zheng/Changen/releases/download/v0.1/changestar1x96_r18_ft_levircd.pth\" to /root/.cache/torch/hub/checkpoints/changestar1x96_r18_ft_levircd.pth\n",
            "100%|██████████| 62.7M/62.7M [00:12<00:00, 5.11MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a40gRmxoqM3",
        "outputId": "73b210bb-fdb0-424a-8348-617dbcaeb24e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Data Test"
      ],
      "metadata": {
        "id": "6D5uBQijwiAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "t1_path = \"/content/drive/MyDrive/Datasets/test_data/t1_rgb/0016.png\"\n",
        "t2_path = \"/content/drive/MyDrive/Datasets/test_data/t2_rgb/0016.png\"\n",
        "\n",
        "# Load the images\n",
        "t1_image = Image.open(t1_path)\n",
        "t2_image = Image.open(t2_path)\n",
        "\n",
        "\n",
        "# Convert the images to numpy arrays\n",
        "t1_array = np.array(t1_image).astype(np.float32) / 255.0\n",
        "t2_array = np.array(t2_image).astype(np.float32) / 255.0\n",
        "\n",
        "# Reorder the dimensions to (channels, height, width)\n",
        "t1_array = torch.tensor(np.transpose(t1_array, (2, 0, 1)))  # (height, width, channels) -> (channels, height, width)\n",
        "t2_array = torch.tensor(np.transpose(t2_array, (2, 0, 1)))  # (height, width, channels) -> (channels, height, width)\n",
        "\n",
        "# Verify the shape\n",
        "print(f\"t1_array shape: {t1_array.shape}\")\n",
        "print(f\"t2_array shape: {t2_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrvL4U7GvmAE",
        "outputId": "7fb6c667-20f6-434e-a64a-e46ef9c7ad7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t1_array shape: torch.Size([3, 512, 512])\n",
            "t2_array shape: torch.Size([3, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_images = torch.cat([t1_array.unsqueeze(0), t2_array.unsqueeze(0)], dim=1)  # [b, tc, h, w]\n",
        "bi_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmRP0NeTxaSA",
        "outputId": "0fdee633-49e7-4634-d119-86621d75f8e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 512, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_images = bi_images.float()\n",
        "bi_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl3jj5UlyDQg",
        "outputId": "771c7d55-c1f1-4c3c-acc3-25160a1432a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.1098, 0.0941, 0.0980,  ..., 0.0745, 0.0824, 0.0667],\n",
              "          [0.1020, 0.0980, 0.0980,  ..., 0.0863, 0.0706, 0.0667],\n",
              "          [0.0706, 0.0706, 0.0706,  ..., 0.0706, 0.0706, 0.0706],\n",
              "          ...,\n",
              "          [0.2039, 0.1412, 0.0824,  ..., 0.1490, 0.1255, 0.0824],\n",
              "          [0.1647, 0.1216, 0.0706,  ..., 0.1451, 0.1216, 0.0667],\n",
              "          [0.1373, 0.0902, 0.0784,  ..., 0.1059, 0.0941, 0.0549]],\n",
              "\n",
              "         [[0.1098, 0.0941, 0.0863,  ..., 0.0745, 0.0863, 0.0627],\n",
              "          [0.0784, 0.0863, 0.0784,  ..., 0.0902, 0.0745, 0.0706],\n",
              "          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0784, 0.0784],\n",
              "          ...,\n",
              "          [0.1922, 0.1647, 0.1451,  ..., 0.1529, 0.1294, 0.0863],\n",
              "          [0.1765, 0.1608, 0.1412,  ..., 0.1137, 0.1098, 0.0667],\n",
              "          [0.1686, 0.1529, 0.1490,  ..., 0.0824, 0.0784, 0.0549]],\n",
              "\n",
              "         [[0.0667, 0.0549, 0.0627,  ..., 0.0471, 0.0549, 0.0392],\n",
              "          [0.0471, 0.0510, 0.0471,  ..., 0.0549, 0.0510, 0.0392],\n",
              "          [0.0431, 0.0431, 0.0510,  ..., 0.0471, 0.0392, 0.0471],\n",
              "          ...,\n",
              "          [0.1216, 0.1059, 0.0667,  ..., 0.0941, 0.0784, 0.0510],\n",
              "          [0.0980, 0.0941, 0.0510,  ..., 0.0824, 0.0667, 0.0431],\n",
              "          [0.0902, 0.0745, 0.0471,  ..., 0.0549, 0.0510, 0.0392]],\n",
              "\n",
              "         [[0.2549, 0.2353, 0.1922,  ..., 0.0824, 0.0902, 0.0706],\n",
              "          [0.2000, 0.2039, 0.1922,  ..., 0.0941, 0.0902, 0.0627],\n",
              "          [0.1843, 0.1765, 0.1647,  ..., 0.0824, 0.0627, 0.0588],\n",
              "          ...,\n",
              "          [0.2902, 0.2000, 0.1647,  ..., 0.1569, 0.1333, 0.1176],\n",
              "          [0.2314, 0.2000, 0.1804,  ..., 0.1882, 0.1294, 0.0902],\n",
              "          [0.1882, 0.1882, 0.1843,  ..., 0.1216, 0.0902, 0.0667]],\n",
              "\n",
              "         [[0.1804, 0.1843, 0.1725,  ..., 0.0941, 0.1059, 0.0824],\n",
              "          [0.1412, 0.1569, 0.1529,  ..., 0.1098, 0.1020, 0.0824],\n",
              "          [0.1412, 0.1412, 0.1490,  ..., 0.0980, 0.0980, 0.0902],\n",
              "          ...,\n",
              "          [0.2471, 0.2078, 0.1961,  ..., 0.1608, 0.1529, 0.1176],\n",
              "          [0.2078, 0.1843, 0.1961,  ..., 0.1686, 0.1333, 0.0902],\n",
              "          [0.1843, 0.1725, 0.1804,  ..., 0.1137, 0.0980, 0.0784]],\n",
              "\n",
              "         [[0.1255, 0.1333, 0.1059,  ..., 0.0588, 0.0667, 0.0510],\n",
              "          [0.0784, 0.0902, 0.0863,  ..., 0.0627, 0.0588, 0.0510],\n",
              "          [0.0667, 0.0745, 0.0549,  ..., 0.0588, 0.0510, 0.0549],\n",
              "          ...,\n",
              "          [0.1647, 0.1333, 0.1059,  ..., 0.1176, 0.1137, 0.0745],\n",
              "          [0.1373, 0.1176, 0.1216,  ..., 0.1098, 0.0902, 0.0667],\n",
              "          [0.1020, 0.1059, 0.1137,  ..., 0.0706, 0.0627, 0.0471]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(bi_images)\n",
        "change_prob = predictions['change_prediction']  # [b, 1, h, w]"
      ],
      "metadata": {
        "id": "hjWhHNyuxkbT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "change_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U98bUp51yLhF",
        "outputId": "005ccdcd-5cc6-4e90-d2a6-673e49d1b87f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[5.6703e-05, 5.0165e-05, 4.4381e-05,  ..., 3.0518e-07,\n",
              "           1.2563e-07, 5.1721e-08],\n",
              "          [7.2644e-05, 6.4830e-05, 5.7858e-05,  ..., 7.4096e-07,\n",
              "           3.6320e-07, 1.7804e-07],\n",
              "          [9.3065e-05, 8.3783e-05, 7.5426e-05,  ..., 1.7990e-06,\n",
              "           1.0500e-06, 6.1285e-07],\n",
              "          ...,\n",
              "          [1.3878e-05, 8.1123e-06, 4.7420e-06,  ..., 4.6735e-05,\n",
              "           4.9292e-05, 5.1989e-05],\n",
              "          [1.5424e-05, 9.4518e-06, 5.7920e-06,  ..., 7.7653e-05,\n",
              "           6.9849e-05, 6.2830e-05],\n",
              "          [1.7142e-05, 1.1012e-05, 7.0744e-06,  ..., 1.2902e-04,\n",
              "           9.8978e-05, 7.5932e-05]]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming change_prob is a 4D tensor with shape [batch_size, 1, height, width]\n",
        "# Apply a threshold to get the binary mask (threshold is commonly set to 0.5)\n",
        "binary_mask = (change_prob >= 0.5).float()  # Thresholding the probabilities at 0.5\n",
        "\n",
        "# You can convert to uint8 for display purposes (values will be 0 or 1)\n",
        "binary_mask_uint8 = (binary_mask * 255).to(torch.uint8)  # Convert to 0 or 255 for image display\n",
        "\n",
        "# Since we have a batch dimension, we can take the first image (batch[0]) and the first channel (change prediction)\n",
        "binary_mask_image = binary_mask_uint8[0, 0, :, :].cpu().numpy()  # Convert to NumPy array for plotting\n"
      ],
      "metadata": {
        "id": "EsKu2iVf0fW7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the binary mask\n",
        "plt.imshow(binary_mask_image, cmap='gray')\n",
        "plt.title(\"Binary Mask\")\n",
        "plt.axis(\"off\")  # Hide the axes for cleaner display\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "SDim7Jx000GC",
        "outputId": "9bc775b4-56ce-4d67-ca25-296d4b554565"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Evaluation"
      ],
      "metadata": {
        "id": "uCAOHwaZ7lfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import imageio.v3 as imageio\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score, f1_score, precision_score, recall_score, accuracy_score, cohen_kappa_score\n",
        ")"
      ],
      "metadata": {
        "id": "p2LuBKCi02EB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths and model setup\n",
        "base_path = '/content/drive/MyDrive/Datasets/test_data/'\n",
        "t1_path = os.path.join(base_path, 't1_rgb')\n",
        "t2_path = os.path.join(base_path, 't2_rgb')\n",
        "gt_path = os.path.join(base_path, 'gt_grayscale')\n",
        "test_out_path = \"/content/drive/MyDrive/Datasets/test_data/\"\n",
        "metrics_out_file = os.path.join(test_out_path, \"metrics_results.json\")"
      ],
      "metadata": {
        "id": "6t5H5wrc7oDO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics function\n",
        "def evaluate_metrics(predicted, ground_truth):\n",
        "    # Flatten both arrays\n",
        "    predicted = predicted.flatten()\n",
        "    ground_truth = ground_truth.flatten()\n",
        "\n",
        "    # Normalize to binary labels if necessary (0 and 1)\n",
        "    if 255 in predicted or 255 in ground_truth:\n",
        "        predicted = (predicted / 255).astype(int)\n",
        "        ground_truth = (ground_truth / 255).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        \"Jaccard Index (IoU)\": jaccard_score(ground_truth, predicted, average=\"binary\"),\n",
        "        \"F1 Score\": f1_score(ground_truth, predicted, average=\"binary\"),\n",
        "        \"Precision\": precision_score(ground_truth, predicted, average=\"binary\"),\n",
        "        \"Recall\": recall_score(ground_truth, predicted, average=\"binary\"),\n",
        "        \"Accuracy\": accuracy_score(ground_truth, predicted),\n",
        "        \"Cohen's Kappa Score\": cohen_kappa_score(ground_truth, predicted)\n",
        "    }\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "0VCsnh6-8TvS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to track the sum of each metric\n",
        "metric_sums = {\n",
        "    \"Jaccard Index (IoU)\": 0,\n",
        "    \"F1 Score\": 0,\n",
        "    \"Precision\": 0,\n",
        "    \"Recall\": 0,\n",
        "    \"Accuracy\": 0,\n",
        "    \"Cohen's Kappa Score\": 0\n",
        "}\n",
        "\n",
        "# Total number of images processed\n",
        "num_images = 0\n",
        "all_metrics = {}\n",
        "\n",
        "for filename in os.listdir(t1_path):\n",
        "    t1_image_path = os.path.join(t1_path, filename)\n",
        "    t2_image_path = os.path.join(t2_path, filename)\n",
        "    gt_image_path = os.path.join(gt_path, filename)\n",
        "\n",
        "    # Check if corresponding files exist\n",
        "    if not os.path.isfile(t2_image_path) or not os.path.isfile(gt_image_path):\n",
        "        print(f\"Missing corresponding file for {filename}\")\n",
        "        continue\n",
        "\n",
        "   # Load the images\n",
        "    t1_image = Image.open(t1_image_path)\n",
        "    t2_image = Image.open(t2_image_path)\n",
        "    gt_image = Image.open(gt_image_path)\n",
        "\n",
        "\n",
        "    # Convert the images to numpy arrays\n",
        "    t1_array = np.array(t1_image).astype(np.float32)\n",
        "    t2_array = np.array(t2_image).astype(np.float32)\n",
        "    gt_image = np.array(gt_image)\n",
        "\n",
        "    # Reorder the dimensions to (channels, height, width)\n",
        "    t1_array = torch.tensor(np.transpose(t1_array, (2, 0, 1)))  # (height, width, channels) -> (channels, height, width)\n",
        "    t2_array = torch.tensor(np.transpose(t2_array, (2, 0, 1)))  # (height, width, channels) -> (channels, height, width)\n",
        "\n",
        "    bi_images = torch.cat([t1_array.unsqueeze(0), t2_array.unsqueeze(0)], dim=1)\n",
        "    bi_images = bi_images.float()\n",
        "\n",
        "    # Model prediction\n",
        "    predictions = model(bi_images)\n",
        "    change_prob = predictions['change_prediction']  # [b, 1, h, w]\n",
        "\n",
        "    # Assuming change_prob is a 4D tensor with shape [batch_size, 1, height, width]\n",
        "    # Apply a threshold to get the binary mask (threshold is commonly set to 0.5)\n",
        "    binary_mask = (change_prob >= 0.5).float()  # Thresholding the probabilities at 0.5\n",
        "\n",
        "    # You can convert to uint8 for display purposes (values will be 0 or 1)\n",
        "    binary_mask_uint8 = (binary_mask * 255).to(torch.uint8)  # Convert to 0 or 255 for image display\n",
        "\n",
        "    # Since we have a batch dimension, we can take the first image (batch[0]) and the first channel (change prediction)\n",
        "    binary_mask_image = binary_mask_uint8[0, 0, :, :].cpu().numpy()  # Convert to NumPy array for plotting\n",
        "\n",
        "\n",
        "    # Save the output change map for visualization\n",
        "    imageio.imwrite(os.path.join(test_out_path, f\"{filename}_change.png\"), binary_mask_image)\n",
        "\n",
        "    # Evaluate metrics\n",
        "    metrics = evaluate_metrics(binary_mask_image, gt_image)\n",
        "    print(f\"Metrics for {filename}: {metrics}\")\n",
        "\n",
        "    # Save metrics for this image\n",
        "    all_metrics[filename] = metrics\n",
        "\n",
        "    # Add metrics to the sums\n",
        "    for metric_name in metrics:\n",
        "        metric_sums[metric_name] += metrics[metric_name]\n",
        "\n",
        "    num_images += 1\n",
        "\n",
        "# Calculate the average of each metric\n",
        "if num_images > 0:\n",
        "    avg_metrics = {metric: metric_sums[metric] / num_images for metric in metric_sums}\n",
        "    print(\"\\nAverage Metrics:\")\n",
        "    for metric, avg_value in avg_metrics.items():\n",
        "        print(f\"{metric}: {avg_value:.4f}\")\n",
        "\n",
        "    # Save metrics to JSON\n",
        "    all_metrics[\"Average\"] = avg_metrics\n",
        "    with open(metrics_out_file, \"w\") as f:\n",
        "        json.dump(all_metrics, f, indent=4)\n",
        "    print(f\"Metrics saved to {metrics_out_file}\")\n",
        "else:\n",
        "    print(\"No images processed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96mJ_Bf8bPI",
        "outputId": "5bbfa3dd-f7a4-45d8-a099-8db26c3544e3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 512)\n",
            "(512, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for 0139_1.png: {'Jaccard Index (IoU)': 0.0, 'F1 Score': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'Accuracy': 0.9928550720214844, \"Cohen's Kappa Score\": 0.0}\n",
            "Metrics for 0049.png: {'Jaccard Index (IoU)': 0.0, 'F1 Score': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'Accuracy': 0.97467041015625, \"Cohen's Kappa Score\": -0.008929490850107413}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0107.png: {'Jaccard Index (IoU)': 0.382183908045977, 'F1 Score': 0.553014553014553, 'Precision': 0.5112107623318386, 'Recall': 0.6022641509433962, 'Accuracy': 0.9950790405273438, \"Cohen's Kappa Score\": 0.5505570895916831}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0016.png: {'Jaccard Index (IoU)': 0.0, 'F1 Score': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'Accuracy': 0.9936904907226562, \"Cohen's Kappa Score\": -0.0020514468228429728}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0139.png: {'Jaccard Index (IoU)': 0.06287987622941761, 'F1 Score': 0.11831981700977334, 'Precision': 0.06460769842171, 'Recall': 0.7016029593094945, 'Accuracy': 0.9676513671875, \"Cohen's Kappa Score\": 0.11329601155108371}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0101.png: {'Jaccard Index (IoU)': 0.0, 'F1 Score': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'Accuracy': 0.8757667541503906, \"Cohen's Kappa Score\": -0.007442954078656028}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0116_1.png: {'Jaccard Index (IoU)': 0.0, 'F1 Score': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'Accuracy': 0.9456596374511719, \"Cohen's Kappa Score\": 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0073.png: {'Jaccard Index (IoU)': 0.0, 'F1 Score': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'Accuracy': 0.9563751220703125, \"Cohen's Kappa Score\": -0.021782226050818032}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0116.png: {'Jaccard Index (IoU)': 0.0025833724753405356, 'F1 Score': 0.005153431717029749, 'Precision': 0.0037250253979004403, 'Recall': 0.008358662613981762, 'Accuracy': 0.9837989807128906, \"Cohen's Kappa Score\": -0.0018042752817539753}\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "Metrics for 0137.png: {'Jaccard Index (IoU)': 0.3200898255311798, 'F1 Score': 0.48495158335514266, 'Precision': 0.8343088698784331, 'Recall': 0.3418188526102195, 'Accuracy': 0.9849853515625, \"Cohen's Kappa Score\": 0.47868528615315153}\n",
            "\n",
            "Average Metrics:\n",
            "Jaccard Index (IoU): 0.0768\n",
            "F1 Score: 0.1161\n",
            "Precision: 0.1414\n",
            "Recall: 0.1654\n",
            "Accuracy: 0.9671\n",
            "Cohen's Kappa Score: 0.1101\n",
            "Metrics saved to /content/drive/MyDrive/Datasets/test_data/metrics_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRn5ka_i2IXB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}